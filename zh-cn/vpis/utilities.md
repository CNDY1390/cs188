---
title: 7.1 效用
parent: 7. 决策网络和 VPIs
nav_order: 1
layout: page
header-includes:
    \pagenumbering{gobble}
---

# 7.1 效用 (Utilities)

在我们对理性智能体的讨论中，效用的概念反复出现。例如，在游戏中，效用值通常是硬连线到游戏中的，智能体使用这些效用值来选择动作。我们现在将讨论生成可行的效用函数需要什么。

理性智能体必须遵循**最大效用原则 (principle of maximum utility)**——它们必须始终选择最大化其期望效用的动作。然而，遵守这一原则只对具有**理性偏好 (rational preferences)** 的智能体有利。为了构建一个非理性偏好的例子，假设存在 3 个对象，$$A$$、$$B$$ 和 $$C$$，我们的智能体目前拥有 $$A$$。假设我们的智能体有以下一组非理性偏好：

- 我们的智能体偏好 $$B$$ 胜过 $$A$$ 加 1 美元
- 我们的智能体偏好 $$C$$ 胜过 $$B$$ 加 1 美元
- 我们的智能体偏好 $$A$$ 胜过 $$C$$ 加 1 美元

一个拥有 $$B$$ 和 $$C$$ 的恶意智能体可以用 $$B$$ 交换我们智能体的 $$A$$ 加一美元，然后用 $$C$$ 交换 $$B$$ 加一美元，然后再用 $$A$$ 交换 $$C$$ 加一美元。我们的智能体刚刚白白损失了 3 美元！通过这种方式，我们的智能体可能会被迫在一个无休止的噩梦般的循环中放弃所有的钱。

现在让我们正确定义偏好的数学语言：

- 如果智能体偏好接收奖品 $$A$$ 而不是接收奖品 $$B$$，这写为 $$A \succ B$$
- 如果智能体对接收 $$A$$ 或 $$B$$ 漠不关心（无差异），这写为 $$A \sim B$$
- **彩票 (lottery)** 是导致不同概率的不同奖品的情况。为了表示以概率 $$p$$ 接收 $$A$$ 和以概率 $$(1-p)$$ 接收 $$B$$ 的彩票，我们写为：

  $$L = [p, A; (1-p), B]$$

为了使一组偏好是理性的，它们必须遵循五个**理性公理 (Axioms of Rationality)**：

- **可排序性 (Orderability)**:  
  $$(A \succ B) \vee (B \succ A) \vee (A \sim B)$$  
  理性智能体必须要么偏好 $$A$$ 或 $$B$$ 中的一个，要么在两者之间无差异。
  
- **传递性 (Transitivity)**:  
  $$(A \succ B) \wedge (B \succ C) \Rightarrow (A \succ C)$$  
  如果理性智能体偏好 $$A$$ 胜过 $$B$$ 且 $$B$$ 胜过 $$C$$，那么它偏好 $$A$$ 胜过 $$C$$。

- **连续性 (Continuity)**:  
  $$A \succ B \succ C \Rightarrow \exists p \: [p, A; (1-p), C] \sim B$$  
  如果理性智能体偏好 $$A$$ 胜过 $$B$$ 但 $$B$$ 胜过 $$C$$，那么可以通过适当选择 $$p$$，在 $$A$$ 和 $$C$$ 之间构建一个彩票 $$L$$，使得智能体在 $$L$$ 和 $$B$$ 之间无差异。

- **可替代性 (Substitutability)**:  
  $$A \sim B \Rightarrow [p, A; (1-p), C] \sim [p, B; (1-p), C]$$  
  在两个奖品 $$A$$ 和 $$B$$ 之间无差异的理性智能体，在仅将 $$A$$ 替换为 $$B$$ 或将 $$B$$ 替换为 $$A$$ 的任何两个彩票之间也是无差异的。

- **单调性 (Monotonicity)**:  
  $$A \succ B \Rightarrow (p \geq q) \Leftrightarrow [p, A; (1-p), B] \succeq [q, A; (1-q), B]$$  
  如果理性智能体偏好 $$A$$ 胜过 $$B$$，那么在仅涉及 $$A$$ 和 $$B$$ 的彩票之间进行选择时，智能体偏好分配给 $$A$$ 最高概率的彩票。

如果智能体满足所有五个公理，那么可以保证智能体的行为可以描述为期望效用的最大化。更具体地说，这意味着存在一个实值**效用函数 (utility function)** $$U$$，当实现时，它将为偏好的奖品分配更大的效用，并且彩票的效用是彩票产生的奖品效用的期望值。这两个陈述可以用两个简洁的数学等价式概括：

$$U(A) \geq U(B) \Leftrightarrow A \succeq B$$

$$U([p_1, S_1; ... ;p_n, S_n]) = \sum_i p_i U(S_i)$$

如果满足这些约束并且选择了适当的算法，实现这种效用函数的智能体保证表现最佳。让我们通过一个具体的例子更详细地讨论效用函数。考虑以下彩票：

$$L = [0.5, \$0; 0.5, \$1000]$$

这代表一个彩票，你以 0.5 的概率获得 \$1000，以 0.5 的概率获得 \$0。现在考虑三个智能体 $$A_1$$、$$A_2$$ 和 $$A_3$$，它们分别具有效用函数 $$U_1(\$x) = x$$、$$U_2(\$x) = \sqrt{x}$$ 和 $$U_3(\$x) = x^2$$。如果这三个智能体中的每一个都面临在参与彩票和接收 \$500 的固定付款之间进行选择，他们会选择哪个？每个智能体参与彩票和接受固定付款的各自效用列于下表：

| **智能体** | **彩票** | **固定付款** |
|-----------|-------------|------------------|
| 1         | 500         | 500              |
| 2         | 15.81       | 22.36            |
| 3         | 500000      | 250000           |

这些彩票的效用值计算如下，利用上面的等式 (2)：

$$U_1(L) = U_1([0.5, \$0; 0.5, \$1000]) = 0.5 \cdot U_1(\$1000) + 0.5 \cdot U_1(\$0) = 0.5 \cdot 1000 + 0.5 \cdot 0 = \boxed{500}$$

$$U_2(L) = U_2([0.5, \$0; 0.5, \$1000]) = 0.5 \cdot U_2(\$1000) + 0.5 \cdot U_2(\$0) = 0.5 \cdot \sqrt{1000} + 0.5 \cdot \sqrt{0} = \boxed{15.81}$$

$$U_3(L) = U_1([0.5, \$0; 0.5, \$1000]) = 0.5 \cdot U_3(\$1000) + 0.5 \cdot U_3(\$0) = 0.5 \cdot 1000^2 + 0.5 \cdot 0^2 = \boxed{500000}$$

有了这些结果，我们可以看到智能体 $$A_1$$ 在参与彩票和接收固定付款之间是无差异的（两种情况的效用相同）。这种智能体被称为**风险中性 (risk-neutral)**。同样，智能体 $$A_2$$ 偏好固定付款而不是彩票，被称为**风险厌恶 (risk-averse)**，智能体 $$A_3$$ 偏好彩票而不是固定付款，被称为**风险偏好 (risk-seeking)**。
