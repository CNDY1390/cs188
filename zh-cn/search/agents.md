---
title: 1.1 Agents
parent: 1. 搜索
nav_order: 1
layout: page
header-includes:
    \pagenumbering{gobble}
lang: zh-cn
---

# 1.1 Agents (智能体)

在人工智能中，我们要解决的核心问题是创建一个理性的 **agent**（智能体），这是一个拥有目标或偏好，并试图执行一系列 **actions**（动作）以在给定这些目标的情况下产生最佳/最优预期结果的实体。理性智能体存在于 **environment**（环境）中，该环境特定于智能体的给定实例。智能体使用传感器与环境交互，并使用执行器对环境采取行动。作为一个非常简单的例子，跳棋智能体的环境是它与对手下棋的虚拟跳棋盘，其中棋子的移动是动作。环境和居住在其中的智能体共同创造了一个 **world**（世界）。

**Reflex agent**（反射智能体）不考虑其行为的后果，而是仅根据世界的当前状态选择动作。这些智能体通常不如 **planning agents**（规划智能体）表现好，规划智能体维护世界模型并使用该模型来模拟执行各种动作。然后，智能体可以确定动作的假设后果并选择最好的一个。这是模拟的“智能”，因为这正是人类在试图确定任何情况下的最佳可能举措时所做的事情——未雨绸缪。

为了定义任务环境，我们使用 **PEAS** (**P**erformance Measure, **E**nvironment, **A**ctuators, **S**ensors)（性能度量、环境、执行器、传感器）描述。性能度量描述了智能体试图增加什么效用。环境总结了智能体在哪里行动以及什么影响智能体。执行器和传感器是智能体对环境采取行动并从中接收信息的方法。

智能体的 **design**（设计）在很大程度上取决于智能体所作用的环境类型。我们可以通过以下方式描述环境的类型：

- 在 *partially observable*（部分可观察）环境中，智能体没有关于状态的完整信息，因此必须对世界状态进行内部估计。这与 *fully observable*（完全可观察）环境形成对比，在完全可观察环境中，智能体拥有关于其状态的完整信息。
- *Stochastic*（随机）环境在转换模型中具有不确定性，即在特定状态下采取动作可能会有多种可能的结果，每种结果都有不同的概率。这与 *deterministic*（确定性）环境形成对比，在确定性环境中，在状态下采取动作具有保证发生的单一结果。
- 在 *multi-agent*（多智能体）环境中，智能体与其他智能体一起行动。因此，智能体可能需要随机化其动作，以避免被其他智能体“预测”。
- 如果环境不随智能体对其采取行动而改变，则称为 *static*（静态）。这与 *dynamic*（动态）环境形成对比，动态环境随着智能体与之交互而改变。
- 如果环境具有 *known physics*（已知物理规律），则转换模型（即使是随机的）对智能体来说是已知的，它可以在规划路径时使用它。如果 *physics are unknown*（物理规律未知），智能体将需要故意采取行动来学习未知的动态。
